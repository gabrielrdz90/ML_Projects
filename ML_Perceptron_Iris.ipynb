{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a75f672",
   "metadata": {},
   "source": [
    "**Gabriel Rodriguez**  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dffbd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# Import a function for plotting decision boudaries\n",
    "from mlxtend.plotting import plot_decision_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "f27bc544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the iris dataset into a pandas DataFrame object\n",
    "df = pd.read_csv(\"iris_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "6439e702",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214d0ee3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad33c119",
   "metadata": {},
   "source": [
    "Filter data: Variables *sepal length* and *petal length* for only *versicolor* and *virginica* species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "97b4684b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.4</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "50            7.0          3.2           4.7          1.4  versicolor\n",
       "51            6.4          3.2           4.5          1.5  versicolor\n",
       "52            6.9          3.1           4.9          1.5  versicolor\n",
       "53            5.5          2.3           4.0          1.3  versicolor\n",
       "54            6.5          2.8           4.6          1.5  versicolor\n",
       "..            ...          ...           ...          ...         ...\n",
       "145           6.7          3.0           5.2          2.3   virginica\n",
       "146           6.3          2.5           5.0          1.9   virginica\n",
       "147           6.5          3.0           5.2          2.0   virginica\n",
       "148           6.2          3.4           5.4          2.3   virginica\n",
       "149           5.9          3.0           5.1          1.8   virginica\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter df for output variables: versicolor and virginica species (rows 50:150)\n",
    "\n",
    "df = df.iloc[50:150]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "c51213c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>petal_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>6.4</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.9</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>6.5</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  petal_length\n",
       "50            7.0           4.7\n",
       "51            6.4           4.5\n",
       "52            6.9           4.9\n",
       "53            5.5           4.0\n",
       "54            6.5           4.6\n",
       "..            ...           ...\n",
       "145           6.7           5.2\n",
       "146           6.3           5.0\n",
       "147           6.5           5.2\n",
       "148           6.2           5.4\n",
       "149           5.9           5.1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select input variables: sepal length and petal length\n",
    "X = df[[\"sepal_length\", \"petal_length\"]]\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "40d09c3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store the labels in an array y\n",
    "y = df['species']\n",
    "\n",
    "# We can leave the original labels and use sklearn perceptron,\n",
    "# but to use mlxtend for plotting we need to encode the labels\n",
    "# versicolor = -1, virginica = 1\n",
    "\n",
    "y = np.where(y == 'versicolor', -1, 1)\n",
    "\n",
    "y\n",
    "\n",
    "# Using this just for the purposes of plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3a729e",
   "metadata": {},
   "source": [
    "Use Sklearn Perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7f2502f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Perceptron()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Perceptron</label><div class=\"sk-toggleable__content\"><pre>Perceptron()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Perceptron()"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate one instance of the Perceptron class\n",
    "clf = Perceptron()\n",
    "\n",
    "# Fit the model to the training data\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "525c89db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1, -1, -1, -1,  1,  1, -1,  1,  1,\n",
       "        1, -1, -1,  1,  1, -1,  1,  1, -1, -1,  1, -1,  1, -1,  1, -1,  1,\n",
       "       -1,  1,  1, -1, -1,  1, -1,  1,  1,  1, -1, -1, -1,  1,  1])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute predict labels on X\n",
    "y_pred = clf.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "66e8dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True False  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      " False False False  True  True False  True  True  True False False  True\n",
      "  True False  True  True False False  True False  True False  True False\n",
      "  True False  True  True False False  True False  True  True  True False\n",
      " False False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Compare actual and predicted labels\n",
    "print(y == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b979c1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-56.5,  74.9]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_   # weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d8bf0749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-38.])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.intercept_ # bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "874d6e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gabri\\anaconda3\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but Perceptron was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get used to using the \"plot_decision_regions() func from mlxtend library\"\n",
    "plt.figure(figsize = (8, 6))\n",
    "\n",
    "# X = x values, your features (to make scatterplot)\n",
    "# y = labels to define classes\n",
    "# clf = classifier (the decision boudary)\n",
    "plot_decision_regions(X.to_numpy(), y, clf = clf) # X.to_numpy is used because the function needs to be in the form of array\n",
    "plt.title(\"Sklearn Perceptron\", fontsize = 18)\n",
    "plt.xlabel(\"sepal length\", fontsize = 15)\n",
    "plt.ylabel(\"petal length\", fontsize = 15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c027c0",
   "metadata": {},
   "source": [
    "**Note:** Graphing the decision region of the sklearn perceptron model reveals that versicolor and virginica species (our 2 classes) are not linearly seperable. There is an overlap of our decision boundary, having one versicolor misclassified as virginica, and a few more virginica misclassified as versicolor. We should also note that in this case, the overlap is easy to visualize due to the fact that there are only two input variables and can therefore graph it in a two dimensional space. Visualization for three input variables is also possible, but having input variables greater than three will be impossible to visualize.   \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d269208a",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Note:** Add one more variable (3 total inputs) using MyPerceptron. Need a 3rd weight. We will not be able to plot as we are using 3 dimensions. We can check our algorithm by comparing yhat to actual y values!  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5cc88d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the iris dataset into a pandas DataFrame object\n",
    "df = pd.read_csv(\"iris_dataset.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a636697d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width     species\n",
       "0            5.1          3.5           1.4          0.2      setosa\n",
       "1            4.9          3.0           1.4          0.2      setosa\n",
       "2            4.7          3.2           1.3          0.2      setosa\n",
       "3            4.6          3.1           1.5          0.2      setosa\n",
       "4            5.0          3.6           1.4          0.2      setosa\n",
       "..           ...          ...           ...          ...         ...\n",
       "95           5.7          3.0           4.2          1.2  versicolor\n",
       "96           5.7          2.9           4.2          1.3  versicolor\n",
       "97           6.2          2.9           4.3          1.3  versicolor\n",
       "98           5.1          2.5           3.0          1.1  versicolor\n",
       "99           5.7          2.8           4.1          1.3  versicolor\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter df for output variables: setosa and versicolor species (rows 0:100)\n",
    "\n",
    "df = df.iloc[0:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "11535c02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 0.2],\n",
       "       [4.9, 3. , 0.2],\n",
       "       [4.7, 3.2, 0.2],\n",
       "       [4.6, 3.1, 0.2],\n",
       "       [5. , 3.6, 0.2],\n",
       "       [5.4, 3.9, 0.4],\n",
       "       [4.6, 3.4, 0.3],\n",
       "       [5. , 3.4, 0.2],\n",
       "       [4.4, 2.9, 0.2],\n",
       "       [4.9, 3.1, 0.1],\n",
       "       [5.4, 3.7, 0.2],\n",
       "       [4.8, 3.4, 0.2],\n",
       "       [4.8, 3. , 0.1],\n",
       "       [4.3, 3. , 0.1],\n",
       "       [5.8, 4. , 0.2],\n",
       "       [5.7, 4.4, 0.4],\n",
       "       [5.4, 3.9, 0.4],\n",
       "       [5.1, 3.5, 0.3],\n",
       "       [5.7, 3.8, 0.3],\n",
       "       [5.1, 3.8, 0.3],\n",
       "       [5.4, 3.4, 0.2],\n",
       "       [5.1, 3.7, 0.4],\n",
       "       [4.6, 3.6, 0.2],\n",
       "       [5.1, 3.3, 0.5],\n",
       "       [4.8, 3.4, 0.2],\n",
       "       [5. , 3. , 0.2],\n",
       "       [5. , 3.4, 0.4],\n",
       "       [5.2, 3.5, 0.2],\n",
       "       [5.2, 3.4, 0.2],\n",
       "       [4.7, 3.2, 0.2],\n",
       "       [4.8, 3.1, 0.2],\n",
       "       [5.4, 3.4, 0.4],\n",
       "       [5.2, 4.1, 0.1],\n",
       "       [5.5, 4.2, 0.2],\n",
       "       [4.9, 3.1, 0.1],\n",
       "       [5. , 3.2, 0.2],\n",
       "       [5.5, 3.5, 0.2],\n",
       "       [4.9, 3.1, 0.1],\n",
       "       [4.4, 3. , 0.2],\n",
       "       [5.1, 3.4, 0.2],\n",
       "       [5. , 3.5, 0.3],\n",
       "       [4.5, 2.3, 0.3],\n",
       "       [4.4, 3.2, 0.2],\n",
       "       [5. , 3.5, 0.6],\n",
       "       [5.1, 3.8, 0.4],\n",
       "       [4.8, 3. , 0.3],\n",
       "       [5.1, 3.8, 0.2],\n",
       "       [4.6, 3.2, 0.2],\n",
       "       [5.3, 3.7, 0.2],\n",
       "       [5. , 3.3, 0.2],\n",
       "       [7. , 3.2, 1.4],\n",
       "       [6.4, 3.2, 1.5],\n",
       "       [6.9, 3.1, 1.5],\n",
       "       [5.5, 2.3, 1.3],\n",
       "       [6.5, 2.8, 1.5],\n",
       "       [5.7, 2.8, 1.3],\n",
       "       [6.3, 3.3, 1.6],\n",
       "       [4.9, 2.4, 1. ],\n",
       "       [6.6, 2.9, 1.3],\n",
       "       [5.2, 2.7, 1.4],\n",
       "       [5. , 2. , 1. ],\n",
       "       [5.9, 3. , 1.5],\n",
       "       [6. , 2.2, 1. ],\n",
       "       [6.1, 2.9, 1.4],\n",
       "       [5.6, 2.9, 1.3],\n",
       "       [6.7, 3.1, 1.4],\n",
       "       [5.6, 3. , 1.5],\n",
       "       [5.8, 2.7, 1. ],\n",
       "       [6.2, 2.2, 1.5],\n",
       "       [5.6, 2.5, 1.1],\n",
       "       [5.9, 3.2, 1.8],\n",
       "       [6.1, 2.8, 1.3],\n",
       "       [6.3, 2.5, 1.5],\n",
       "       [6.1, 2.8, 1.2],\n",
       "       [6.4, 2.9, 1.3],\n",
       "       [6.6, 3. , 1.4],\n",
       "       [6.8, 2.8, 1.4],\n",
       "       [6.7, 3. , 1.7],\n",
       "       [6. , 2.9, 1.5],\n",
       "       [5.7, 2.6, 1. ],\n",
       "       [5.5, 2.4, 1.1],\n",
       "       [5.5, 2.4, 1. ],\n",
       "       [5.8, 2.7, 1.2],\n",
       "       [6. , 2.7, 1.6],\n",
       "       [5.4, 3. , 1.5],\n",
       "       [6. , 3.4, 1.6],\n",
       "       [6.7, 3.1, 1.5],\n",
       "       [6.3, 2.3, 1.3],\n",
       "       [5.6, 3. , 1.3],\n",
       "       [5.5, 2.5, 1.3],\n",
       "       [5.5, 2.6, 1.2],\n",
       "       [6.1, 3. , 1.4],\n",
       "       [5.8, 2.6, 1.2],\n",
       "       [5. , 2.3, 1. ],\n",
       "       [5.6, 2.7, 1.3],\n",
       "       [5.7, 3. , 1.2],\n",
       "       [5.7, 2.9, 1.3],\n",
       "       [6.2, 2.9, 1.3],\n",
       "       [5.1, 2.5, 1.1],\n",
       "       [5.7, 2.8, 1.3]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choosing sepal length, sepal width, and petal width as our 3 input\n",
    "# variables. \n",
    "\n",
    "X = df[[\"sepal_length\", \"sepal_width\", \"petal_width\"]].to_numpy()  # Convert to array for use in MyPerceptron\n",
    "\n",
    "# By converting data to array form we can use linear algebra calculations on our data\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a4b99a",
   "metadata": {},
   "source": [
    "**Modify MyPerceptron to incorporate a third variable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "4c96d343",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPerceptron(object):\n",
    "    # These are our hyperparameters that are given and will remain constant\n",
    "    def __init__(self, eta = 0.5, epochs = 50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.w1 = np.random.rand(1)\n",
    "        self.w2 = np.random.rand(1)\n",
    "        \n",
    "        ### MODIFICATION ###\n",
    "        self.w3 = np.random.rand(1) # 3rd weight for 3rd variable\n",
    "        \n",
    "        self.b = np.random.rand(1)\n",
    "        \n",
    "        self.errors = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            # We are corresponding the xvalues (X) witht the appropriate output (y)\n",
    "            for xi, yi in zip(X, y):\n",
    "                \n",
    "                update = self.eta * (self.predict(xi) - yi)\n",
    "                self.w1 = self.w1 - update*xi[0] # First component of x\n",
    "                self.w2 = self.w2 - update*xi[1] # Second component of x\n",
    "                \n",
    "                #### MODIFICATION ###\n",
    "                self.w3 = self.w3 - update*xi[2] ### Third component of x\n",
    "                \n",
    "                self.b = self.b - update\n",
    "                \n",
    "                # If the update is NOT equal to zero, the datapoint has been misclassified and using the\n",
    "                # int( int != 0) function will tabulate everytime that this occurs!\n",
    "                errors = errors + int(update != 0)\n",
    "                \n",
    "            # Updating the number of errors list\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def weighted_sum(self, x):\n",
    "        ### MODIFICATION: Make sure to add 3rd weight for linear algebra calculations\n",
    "        self.w = np.array([self.w1, self.w2, self.w3])  \n",
    "        \n",
    "        # Using linear algebra we are using the dot product between w and x\n",
    "        return np.dot(x, self.w) + self.b\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # This is our sign() function\n",
    "        return np.where(self.weighted_sum(x) > 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "c7e6a540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyPerceptron at 0x2b895934070>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate one instance of the MODIFIED My_Perceptron class\n",
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f98151f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1],\n",
       "       [ 1]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict labels on X\n",
    "y_pred = my_clf.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "421c2817",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping array to have the same dimension of y values!\n",
    "y_pred = y_pred.reshape(100)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "8ce40c35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Compare actual and predicted labels\n",
    "print(y == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260a1c9f",
   "metadata": {},
   "source": [
    "Check the bias and weights of the modified model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "14b02249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bias: [-0.48148122]\n",
      "Model weights: [[ 1.50546368]\n",
      " [-4.07961563]\n",
      " [ 3.6199931 ]]\n"
     ]
    }
   ],
   "source": [
    "# Bias\n",
    "print(f'Model bias: {my_clf.b}')\n",
    "\n",
    "# Weights\n",
    "print(f'Model weights: {my_clf.w}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf301758",
   "metadata": {},
   "source": [
    "**Note:** As stated previously, we are unable to two-dimensionally graph our modified model decision boundary. Having three input variables we could potentially graph the decision bounday, in this case it would be a plane (not a line as is the case for two input variables), but it would have to be graphed three-dimensionally.  \n",
    "\n",
    "To check the performance of our modified model we compare the predicted output (y values) with the actual values to determine if each individual classification was correct or not. Running our modified model above and making the comparison, we can see that our model is able to accurately classify each species of setosa and versicolor based on sepal width, sepal length, and petal width.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed20a16a",
   "metadata": {},
   "source": [
    "### (c) Try to generalize My_Perceptron code so it could be used for any number of inputs. \n",
    "(Hint: Recall, that for a list ```w``` we can use ```w[-1]``` and ```w[:-1]``` to access the last value in the list and all the values expect the very last value. Also, use ``` np.dot```, NumPy dot product, to compute the pre-activation value of $z$.)\n",
    "\n",
    "**Note:** Store weights in a vector! No loop needed. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efd63b9",
   "metadata": {},
   "source": [
    "**Modify original perceptron model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "859bb245",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPerceptron(object):\n",
    "    # These are our hyperparameters that are given and will remain constant\n",
    "    def __init__(self, eta = 0.5, epochs = 50):\n",
    "        self.eta = eta\n",
    "        self.epochs = epochs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        ### MODIFICATION ###\n",
    "        ## Create vectors to store weights and biases ##\n",
    "        \n",
    "        # The size of weight vector must be number of variables \n",
    "        self.w = np.random.rand(X.shape[1])  #X.shape[1] to obtain number of col/variables \n",
    "        \n",
    "        # The size of bias vector should equal the number of desired output\n",
    "        self.b = np.random.rand(X.shape[1])\n",
    "        \n",
    "        # Iniate empty list to keep track of error value\n",
    "        self.errors = []\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            errors = 0\n",
    "            # We are corresponding the xvalues (X) with the appropriate output (y)\n",
    "            for xi, yi in zip(X, y):\n",
    "                \n",
    "                # Use self.predict method and chosen eta to calculate updated value\n",
    "                update = self.eta * (self.predict(xi) - yi)\n",
    "                \n",
    "                # choosing all of the features \n",
    "                self.w[0:] = self.w[0:] - update*xi \n",
    "                # Update the bias\n",
    "                self.b = self.b - update\n",
    "                \n",
    "                # If the update is NOT equal to zero, the datapoint has been misclassified and using the\n",
    "                # int( int != 0) function will tabulate everytime that this occurs!\n",
    "                errors = errors + int(update != 0)\n",
    "                \n",
    "            # Updating the number of errors list\n",
    "            if errors == 0:\n",
    "                return self\n",
    "            else:\n",
    "                self.errors.append(errors)\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    \n",
    "    def weighted_sum(self, x):\n",
    "        \n",
    "        # Using linear algebra we are using the dot product between w and x\n",
    "        return np.dot(x, self.w[0:]) + self.b[0]\n",
    "    \n",
    "    def predict(self, x):\n",
    "        # This is our sign() function\n",
    "        # Assigns either 1 or -1 value based on whether weighted sum is positive or negative\n",
    "        return np.where(self.weighted_sum(x) > 0.0, 1, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e31099",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Use the generalized model to classify setosa and versicolor by using 2 and 4 variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "57769483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need only setosa and versicolor which are the first 100 rows\n",
    "\n",
    "df = df.iloc[:100]\n",
    "\n",
    "# Store the labels in y\n",
    "y = df['species']\n",
    "\n",
    "# We can leave the original labels and use sklearn perceptron,\n",
    "# but to use mlxtend for plotting we need to encode the labels\n",
    "# setosa = -1, versicolor = 1\n",
    "\n",
    "y = np.where(y == 'setosa', -1, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1d91f",
   "metadata": {},
   "source": [
    "**Using 2 variables**  \n",
    "\n",
    "To test our generalized My_Perceptron class we will use sepal length and petal length to classify setosa and versicolor. We will use this example as we know it is linearly seperable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "7f873ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Choosing all 4 variables\n",
    "\n",
    "X = df[[\"sepal_length\", \"petal_length\"]].to_numpy()  # Convert to array for use in MyPerceptron\n",
    "\n",
    "# By converting data to array form we can use linear algebra calculations on our data\n",
    "\n",
    "\n",
    "# Instantiate one instance of the MODIFIED My_Perceptron class\n",
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(X, y)\n",
    "\n",
    "# Predict labels on X\n",
    "y_pred = my_clf.predict(X)\n",
    "\n",
    "\n",
    "# Compare actual and predicted labels\n",
    "print(y == y_pred.reshape(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "0c62f2ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.MyPerceptron at 0x2b895d934f0>"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate one instance of the MODIFIED My_Perceptron class\n",
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "f7bf3a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict labels on X\n",
    "y_pred = my_clf.predict(X)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7d70e605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshaping array to have the same dimension of y values!\n",
    "y_pred = y_pred.reshape(100)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ceaea1a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Compare actual and predicted labels\n",
    "print(y == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefd25ba",
   "metadata": {},
   "source": [
    "--- \n",
    "**Using the previous 3 variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "274452a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Choosing all 4 variables\n",
    "\n",
    "X = df[[\"sepal_length\", \"sepal_width\", \"petal_width\"]].to_numpy()  # Convert to array for use in MyPerceptron\n",
    "\n",
    "# By converting data to array form we can use linear algebra calculations on our data\n",
    "\n",
    "\n",
    "# Instantiate one instance of the MODIFIED My_Perceptron class\n",
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(X, y)\n",
    "\n",
    "# Predict labels on X\n",
    "y_pred = my_clf.predict(X)\n",
    "\n",
    "\n",
    "# Compare actual and predicted labels\n",
    "print(y == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4cf1ec",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Using 4 variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "35866f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Choosing all 4 variables\n",
    "\n",
    "X = df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]].to_numpy()  # Convert to array for use in MyPerceptron\n",
    "\n",
    "# By converting data to array form we can use linear algebra calculations on our data\n",
    "\n",
    "\n",
    "# Instantiate one instance of the MODIFIED My_Perceptron class\n",
    "my_clf = MyPerceptron()\n",
    "\n",
    "# Call the fit method \n",
    "my_clf.fit(X, y)\n",
    "\n",
    "# Predict labels on X\n",
    "y_pred = my_clf.predict(X)\n",
    "\n",
    "\n",
    "# Compare actual and predicted labels\n",
    "print(y == y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa243184",
   "metadata": {},
   "source": [
    "**Note:** Our generalized perceptron model is accurately classifying setosa and versicolor species using 2, 3, and 4 features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
